{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84895,"databundleVersionId":10008389,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Explore Mental Health Data\nYour Goal: Your goal is to use data from a mental health survey to explore factors that may cause individuals to experience depression.\n\nEvaluation: Submissions are evaluated using **Accuracy Score**.","metadata":{}},{"cell_type":"markdown","source":"# Preparation","metadata":{}},{"cell_type":"markdown","source":"## Load libraries","metadata":{}},{"cell_type":"code","source":"!pip install -U lightautoml[all]","metadata":{"trusted":true,"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2024-11-27T14:32:48.694829Z","iopub.execute_input":"2024-11-27T14:32:48.695410Z","iopub.status.idle":"2024-11-27T14:36:09.508322Z","shell.execute_reply.started":"2024-11-27T14:32:48.695353Z","shell.execute_reply":"2024-11-27T14:36:09.505643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd              # For data manipulation and analysis\nimport numpy as np               # For numerical computing\nfrom datetime import datetime\nimport scipy.stats as stats      # For statistical analysis\nimport math\nimport matplotlib                # For plotting and visualization\nimport matplotlib.pyplot as plt  \nfrom pandas.plotting import parallel_coordinates\nimport seaborn as sns            # For statistical data visualization\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:36:09.511767Z","iopub.execute_input":"2024-11-27T14:36:09.512440Z","iopub.status.idle":"2024-11-27T14:36:10.943677Z","shell.execute_reply.started":"2024-11-27T14:36:09.512351Z","shell.execute_reply":"2024-11-27T14:36:10.942591Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from lightautoml.automl.presets.tabular_presets import TabularAutoML\nfrom lightautoml.tasks import Task\nimport torch\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:36:10.944874Z","iopub.execute_input":"2024-11-27T14:36:10.945320Z","iopub.status.idle":"2024-11-27T14:36:43.747425Z","shell.execute_reply.started":"2024-11-27T14:36:10.945287Z","shell.execute_reply":"2024-11-27T14:36:43.746158Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# For machine learning\nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost as cb\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier, Pool\n\nfrom lightgbm import early_stopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (accuracy_score, precision_score, recall_score, roc_auc_score,\n                             f1_score, confusion_matrix, classification_report)\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.compose import ColumnTransformer\nimport optuna","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:36:43.749621Z","iopub.execute_input":"2024-11-27T14:36:43.750344Z","iopub.status.idle":"2024-11-27T14:36:43.764724Z","shell.execute_reply.started":"2024-11-27T14:36:43.750303Z","shell.execute_reply":"2024-11-27T14:36:43.763461Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load datasets","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/playground-series-s4e11/train.csv')\ndf_test = pd.read_csv('/kaggle/input/playground-series-s4e11/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:36:43.768137Z","iopub.execute_input":"2024-11-27T14:36:43.768534Z","iopub.status.idle":"2024-11-27T14:36:44.776005Z","shell.execute_reply.started":"2024-11-27T14:36:43.768498Z","shell.execute_reply":"2024-11-27T14:36:44.774851Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"print('#####Train dataset structure#####')\nprint(df_train.info())\nprint('#####Test dataset structure#####')\nprint(df_test.info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:36:44.777613Z","iopub.execute_input":"2024-11-27T14:36:44.778113Z","iopub.status.idle":"2024-11-27T14:36:45.147210Z","shell.execute_reply.started":"2024-11-27T14:36:44.778033Z","shell.execute_reply":"2024-11-27T14:36:45.145395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:36:45.148963Z","iopub.execute_input":"2024-11-27T14:36:45.149508Z","iopub.status.idle":"2024-11-27T14:36:45.181070Z","shell.execute_reply.started":"2024-11-27T14:36:45.149466Z","shell.execute_reply":"2024-11-27T14:36:45.179883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_cols = [col for col in df_test.columns if df_test[col].dtypes in ['int', 'float']]\ncat_cols = [col for col in df_test.columns if col not in num_cols]\nprint(num_cols, cat_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:36:45.182572Z","iopub.execute_input":"2024-11-27T14:36:45.183030Z","iopub.status.idle":"2024-11-27T14:36:45.190793Z","shell.execute_reply.started":"2024-11-27T14:36:45.182982Z","shell.execute_reply":"2024-11-27T14:36:45.189421Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Categorical Data","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(5, 2, figsize=(20, 30))\n \nfor i, col in enumerate(cat_cols):\n    plt.subplots_adjust(top = 0.85)\n    ax = sns.histplot(data = df_train, \n                x = col, \n                hue = 'Depression',\n                ax = axes[i // 2, i % 2])\n\nfig.tight_layout(h_pad=2)\nplt.subplots_adjust(top=0.92)\nplt.suptitle('Categorical Feature Distributions by Depression Status', fontsize=16)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:36:45.192170Z","iopub.execute_input":"2024-11-27T14:36:45.192518Z","iopub.status.idle":"2024-11-27T14:36:56.307321Z","shell.execute_reply.started":"2024-11-27T14:36:45.192484Z","shell.execute_reply":"2024-11-27T14:36:56.305970Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Observations**\n- There are many data types in the features - int64, float64, and object\n- There are null values in these features in both train and test datasets -\n    - Major NA value proportion `Profession`, `Academic Pressure`, `Work Pressure`, `CGPA`, `Study Satisfaction`, `Job Satisfaction`\n    - Minor NA value proportion `Dietary Habits`, `Degree`\n- Categorical Features have a lot of low frequency categories\n- Work and Academic columns are quite overlapped\n- `Sleep Duration` has too many irrelevant answers\n\n**Actions**\n- Binary Code for `Gender`, `Have you ever had suicidal thoughts ?`, `Family History of Mental Illness`\n- Engineer columns to simplify `Profession` with `Working Professional or Student`, `Academic Pressure` with `Work Pressure`, `Academic Satisfaction` with `Work Satisfaction`","metadata":{}},{"cell_type":"markdown","source":"## Numerical Data","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(20, 15))\n\nfor i, col in enumerate(num_cols):\n    ax = sns.histplot(data=df_train,\n                      x=col,\n                      bins=20,\n                      ax=axes[i // 3, i % 3])\n    ax.bar_label(ax.containers[1])\n\nfig.tight_layout(h_pad=2)\nplt.subplots_adjust(top=0.92)\nplt.suptitle('Numerical Feature Distributions', fontsize=16)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:36:56.309040Z","iopub.execute_input":"2024-11-27T14:36:56.309550Z","iopub.status.idle":"2024-11-27T14:37:00.063267Z","shell.execute_reply.started":"2024-11-27T14:36:56.309503Z","shell.execute_reply":"2024-11-27T14:37:00.061968Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"df = pd.concat([df_train, df_test])\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:00.064689Z","iopub.execute_input":"2024-11-27T14:37:00.065018Z","iopub.status.idle":"2024-11-27T14:37:00.119676Z","shell.execute_reply.started":"2024-11-27T14:37:00.064986Z","shell.execute_reply":"2024-11-27T14:37:00.117857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"diet_map = {\n        'Healthy': 2,\n        'Moderate': 1\n    }\ngender_map = {\n        'Female': 1,\n        'Male': 0\n    }\nprofession_map = {\n        'Working Professional': 1,\n        'Student': 0\n    }\nsleep_map = {\n        'Very Short ': 1,\n        'Short': 2,\n        'Recommended': 4,\n        'Long': 3,\n        'Irregular': 0\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:00.121577Z","iopub.execute_input":"2024-11-27T14:37:00.122120Z","iopub.status.idle":"2024-11-27T14:37:00.130399Z","shell.execute_reply.started":"2024-11-27T14:37:00.122065Z","shell.execute_reply":"2024-11-27T14:37:00.129133Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def feature_engineering(df):\n    df['Suicidal Thoughts'] = df['Have you ever had suicidal thoughts ?'].apply(lambda x: 1 if x == 'Yes' else 0)\n    df['Family History'] = df['Family History of Mental Illness'].apply(lambda x: 1 if x == 'Yes' else 0)\n    # Name \n    mean_target_per_name = df.groupby('Name')['Depression'].mean()\n    df['Name'] = df['Name'].map(mean_target_per_name)\n    # Gender\n    df['Gender'] = df['Gender'].map(gender_map).fillna(0).astype(int)\n    # Age\n    \n    # City \n    mean_target_per_city = df.groupby('City')['Depression'].mean()\n    df['City'] = df['City'].map(mean_target_per_city)\n    # Work or Student\n    df['Working Professional or Student'] = df['Working Professional or Student'].map(profession_map).fillna(0).astype(int)\n    df['Profession'].fillna('Student', inplace = True)\n    mean_target_per_prof = df.groupby('Profession')['Depression'].mean()\n    df['Profession'] = df['Profession'].map(mean_target_per_prof)\n    # Pressure\n    df['Academic Pressure'].fillna(0, inplace = True)\n    df['Work Pressure'].fillna(0, inplace = True)\n    df['Life Pressure'] = df['Academic Pressure'] + df['Work Pressure']\n    # Satisfaction\n    df['Study Satisfaction'].fillna(0, inplace = True)\n    df['Job Satisfaction'].fillna(0, inplace = True)\n    df['Life Satisfaction'] = df['Study Satisfaction'] + df['Job Satisfaction']\n    # CGPA\n    df['CGPA'].fillna(10, inplace = True)\n\n    # Sleep\n    def bucketize_sleep_duration(val):\n        if '1-' in val or '2-' in val or '3-' in val:\n            return \"Very Short\"\n        elif '4-' in val or '5-' in val:\n            return \"Short\"\n        elif '7-' in val or '8-' in val:\n            return \"Recommended\"\n        elif '9-' in val or '10-' in val or 'More' in val:\n            return \"Long\"\n        else:\n            return \"Irregular\"\n    df['Sleep Length'] = df['Sleep Duration'].apply(bucketize_sleep_duration)\n    df['Healthy Sleep'] = df['Sleep Length'].map(sleep_map).fillna(0).astype(int)\n    \n    # Diet\n    df['Dietary Habits'] = df['Dietary Habits'].map(diet_map).fillna(0).astype(int)\n    \n    # Degree \n    mean_target_per_degree = df.groupby('Degree')['Depression'].mean()\n    df['Degree'] = df['Degree'].map(mean_target_per_degree)\n\n    # Finance\n    financial_stress_mean  = df['Financial Stress'].mean()\n    df['Financial Stress'].fillna(financial_stress_mean, inplace=True)\n\n    # Statistical Features\n    df['academic_pressure__age'] =  df['Age'] *  df['Academic Pressure']\n    df['work_pressure__age'] =  df['Age'] *  df['Work Pressure']\n    df['life_pressure__age'] =  df['Age'] *  df['Life Pressure']\n    df['academic_pressure__age_per_work_pressure__age'] = df['academic_pressure__age']*df['work_pressure__age']\n    df['pressure_satisfaction_prof'] = df['Work Pressure']*df['Job Satisfaction']\n    df['pressure_saticfaction_stud'] =  df['Academic Pressure'] * df['Study Satisfaction']\n    df['pressure_satisfaction_prof_per_work'] = df['Work Pressure']*df['Job Satisfaction']*(df['Work/Study Hours']+1e-6)\n    df['pressure_saticfaction_stud_per_study'] =  df[\"Academic Pressure\"] *  df['Study Satisfaction']*df['Work/Study Hours']\n    df['work_financial_pressure'] =  df['Work Pressure'] * df['Financial Stress']\n    df['work_financial_pressure_satisfaction_work'] =df['Job Satisfaction']*(df['work_financial_pressure'] + 1e-6)\n    df['work_financial_pressure_satisfaction_work'] = df['Study Satisfaction']*(df['work_financial_pressure']+ 1e-6)\n    \n    # Drop columns\n    df.drop(['Have you ever had suicidal thoughts ?'], axis=1, inplace=True)\n    df.drop(['Family History of Mental Illness'], axis=1, inplace=True)\n    df.drop(['Sleep Length'], axis=1, inplace=True)\n    df.drop(['Sleep Duration'], axis=1, inplace=True)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:00.132029Z","iopub.execute_input":"2024-11-27T14:37:00.132534Z","iopub.status.idle":"2024-11-27T14:37:00.153100Z","shell.execute_reply.started":"2024-11-27T14:37:00.132481Z","shell.execute_reply":"2024-11-27T14:37:00.151860Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_engineering(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:00.158549Z","iopub.execute_input":"2024-11-27T14:37:00.159632Z","iopub.status.idle":"2024-11-27T14:37:01.073329Z","shell.execute_reply.started":"2024-11-27T14:37:00.159577Z","shell.execute_reply":"2024-11-27T14:37:01.072024Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.drop(['id'], axis=1, inplace=True)\ndf_train_processed = df[:140700]\ndf_train_processed.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:01.074829Z","iopub.execute_input":"2024-11-27T14:37:01.075220Z","iopub.status.idle":"2024-11-27T14:37:01.137673Z","shell.execute_reply.started":"2024-11-27T14:37:01.075181Z","shell.execute_reply":"2024-11-27T14:37:01.136524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test_processed = df[140700:]\ndf_test_processed.drop(['Depression'], axis=1, inplace=True)\ndf_test_processed.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:01.139127Z","iopub.execute_input":"2024-11-27T14:37:01.139466Z","iopub.status.idle":"2024-11-27T14:37:01.185238Z","shell.execute_reply.started":"2024-11-27T14:37:01.139433Z","shell.execute_reply":"2024-11-27T14:37:01.183948Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Machine Learning","metadata":{}},{"cell_type":"markdown","source":"## Train Test Split","metadata":{}},{"cell_type":"code","source":"X = df_train_processed.drop(columns = ['Depression'] , axis = 1)\ny = df_train_processed['Depression']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:01.187023Z","iopub.execute_input":"2024-11-27T14:37:01.187907Z","iopub.status.idle":"2024-11-27T14:37:01.222111Z","shell.execute_reply.started":"2024-11-27T14:37:01.187846Z","shell.execute_reply":"2024-11-27T14:37:01.220879Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split the dataset into training and validation sets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:01.223450Z","iopub.execute_input":"2024-11-27T14:37:01.223794Z","iopub.status.idle":"2024-11-27T14:37:01.311041Z","shell.execute_reply.started":"2024-11-27T14:37:01.223740Z","shell.execute_reply":"2024-11-27T14:37:01.309974Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" \n    Iterate through all the columns of a dataframe and modify the data type\n    to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if pd.api.types.is_numeric_dtype(df[col]):\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if pd.api.types.is_integer_dtype(df[col]):\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                else:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('object')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:01.312412Z","iopub.execute_input":"2024-11-27T14:37:01.312755Z","iopub.status.idle":"2024-11-27T14:37:01.324332Z","shell.execute_reply.started":"2024-11-27T14:37:01.312720Z","shell.execute_reply":"2024-11-27T14:37:01.323125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train_processed = reduce_mem_usage(df_train_processed)\ndf_test_processed = reduce_mem_usage(df_test_processed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:01.325844Z","iopub.execute_input":"2024-11-27T14:37:01.326254Z","iopub.status.idle":"2024-11-27T14:37:01.487813Z","shell.execute_reply.started":"2024-11-27T14:37:01.326220Z","shell.execute_reply":"2024-11-27T14:37:01.486649Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split the dataset into training and validation sets\ndf_train_split, df_valid_split = train_test_split(df_train_processed, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:01.489268Z","iopub.execute_input":"2024-11-27T14:37:01.489671Z","iopub.status.idle":"2024-11-27T14:37:01.537771Z","shell.execute_reply.started":"2024-11-27T14:37:01.489633Z","shell.execute_reply":"2024-11-27T14:37:01.536830Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = df_train_split.drop(columns = ['Depression'] , axis = 1)\ny_train = df_train_split['Depression']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:01.539130Z","iopub.execute_input":"2024-11-27T14:37:01.539494Z","iopub.status.idle":"2024-11-27T14:37:01.550262Z","shell.execute_reply.started":"2024-11-27T14:37:01.539461Z","shell.execute_reply":"2024-11-27T14:37:01.549199Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_valid = df_valid_split.drop(columns = ['Depression'] , axis = 1)\ny_valid = df_valid_split['Depression']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:01.552439Z","iopub.execute_input":"2024-11-27T14:37:01.552906Z","iopub.status.idle":"2024-11-27T14:37:01.561000Z","shell.execute_reply.started":"2024-11-27T14:37:01.552850Z","shell.execute_reply":"2024-11-27T14:37:01.559842Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Light AutoML","metadata":{}},{"cell_type":"code","source":"def map_class(x, task, reader):\n    if task.name == 'multiclass':\n        return reader[x]\n    else:\n        return x\n\nmapped = np.vectorize(map_class)\n\ndef score(task, y_true, y_pred):\n    if task.name == 'binary':\n        return roc_auc_score(y_true, y_pred)\n    elif task.name == 'multiclass':\n        return accuracy_score(y_true, np.argmax(y_pred, 1))\n    elif task.name == 'reg' or task.name == 'multi:reg':\n        return median_absolute_error(y_true, y_pred)\n    else:\n        raise 'Task is not correct.'\n        \ndef take_pred_from_task(pred, task):\n    if task.name == 'binary' or task.name == 'reg':\n        return pred[:, 0]\n    elif task.name == 'multiclass' or task.name == 'multi:reg':\n        return pred\n    else:\n        raise 'Task is not correct.'\n        \ndef use_plr(USE_PLR):\n    if USE_PLR:\n        return \"plr\"\n    else:\n        return \"cont\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:01.562442Z","iopub.execute_input":"2024-11-27T14:37:01.562802Z","iopub.status.idle":"2024-11-27T14:37:01.572982Z","shell.execute_reply.started":"2024-11-27T14:37:01.562766Z","shell.execute_reply":"2024-11-27T14:37:01.571757Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"RANDOM_STATE = 42\nN_THREADS = os.cpu_count()\nnp.random.seed(RANDOM_STATE)\ntorch.set_num_threads(N_THREADS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:01.574426Z","iopub.execute_input":"2024-11-27T14:37:01.574850Z","iopub.status.idle":"2024-11-27T14:37:01.592401Z","shell.execute_reply.started":"2024-11-27T14:37:01.574814Z","shell.execute_reply":"2024-11-27T14:37:01.591508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# task = Task('binary') \n# autodl = TabularAutoML(\n#     task = task, \n#     timeout = 9 * 3600,\n#     cpu_limit = os.cpu_count(),\n#     general_params = {\"use_algos\": [['resnet']]}, # ['nn', 'mlp', 'dense', 'denselight', 'resnet', 'snn', 'node', 'autoint', 'fttransformer'] or custom torch model\n#     nn_params = {\n#         \"n_epochs\": 10, \n#         \"bs\": 512, \n#         \"num_workers\": 0, \n#         \"path_to_save\": None, \n#         \"freeze_defaults\": True,\n#         \"cont_embedder\": 'plr',\n#         'cat_embedder': 'weighted',\n#         \"hidden_size\": 64,\n#         'hid_factor': [4, 6],\n#         'block_config': [4, 4],\n#         'embedding_size': 64, \n#         'stop_by_metric': True,\n#         'verbose_bar': True,\n#         \"snap_params\": { 'k': 2, 'early_stopping': True, 'patience': 2, 'swa': True }\n#     },\n#     nn_pipeline_params = {\"use_qnt\": False, \"use_te\": True},\n#     reader_params = {'n_jobs': os.cpu_count(), 'cv': 5, 'random_state': 42, 'advanced_roles': True}\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:01.593409Z","iopub.execute_input":"2024-11-27T14:37:01.593733Z","iopub.status.idle":"2024-11-27T14:37:01.614001Z","shell.execute_reply.started":"2024-11-27T14:37:01.593701Z","shell.execute_reply":"2024-11-27T14:37:01.613072Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# out_of_fold_predictions = autodl.fit_predict(\n#     df_train_split,\n#     roles = {\n#         'target': 'Depression',\n#     }, \n#     verbose = 3\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:01.616227Z","iopub.execute_input":"2024-11-27T14:37:01.617069Z","iopub.status.idle":"2024-11-27T14:37:01.635197Z","shell.execute_reply.started":"2024-11-27T14:37:01.617007Z","shell.execute_reply":"2024-11-27T14:37:01.634174Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"task = Task('binary') \nautoml = TabularAutoML(\n    task = task, \n    timeout = 9 * 3600,\n    cpu_limit = os.cpu_count(),\n    nn_params = {\n    'stop_by_metric': True,\n    'verbose_bar': True},\n    nn_pipeline_params = {\"use_qnt\": False, \"use_te\": False},\n    reader_params = {'n_jobs': os.cpu_count(), 'cv': 10, 'random_state': 42, 'advanced_roles': True}\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:01.638131Z","iopub.execute_input":"2024-11-27T14:37:01.639769Z","iopub.status.idle":"2024-11-27T14:37:01.686636Z","shell.execute_reply.started":"2024-11-27T14:37:01.639725Z","shell.execute_reply":"2024-11-27T14:37:01.685553Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"out_of_fold_predictions = automl.fit_predict(\n    df_train_processed,\n    roles = {\n        'target': 'Depression',\n    }, \n    verbose = 3\n)","metadata":{"trusted":true,"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2024-11-27T14:37:01.687923Z","iopub.execute_input":"2024-11-27T14:37:01.688355Z","iopub.status.idle":"2024-11-27T15:00:22.939797Z","shell.execute_reply.started":"2024-11-27T14:37:01.688309Z","shell.execute_reply":"2024-11-27T15:00:22.937895Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predicted_classes = (out_of_fold_predictions.data.flatten() > 0.5).astype(int)\ntrue_labels = df_train_processed['Depression'].values.astype(int)\n\n# Calculate Accuracy Score on validation data\naccuracy = accuracy_score(true_labels, predicted_classes)\nprint(\"Accuracy Score on Validation Data:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:00:22.942501Z","iopub.execute_input":"2024-11-27T15:00:22.942981Z","iopub.status.idle":"2024-11-27T15:00:22.967998Z","shell.execute_reply.started":"2024-11-27T15:00:22.942936Z","shell.execute_reply":"2024-11-27T15:00:22.966544Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred_proba_automl_1 = automl.predict(df_valid_split).data[:, 0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:00:22.969532Z","iopub.execute_input":"2024-11-27T15:00:22.969863Z","iopub.status.idle":"2024-11-27T15:00:31.990481Z","shell.execute_reply.started":"2024-11-27T15:00:22.969832Z","shell.execute_reply":"2024-11-27T15:00:31.989506Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## XGBoost","metadata":{}},{"cell_type":"code","source":"# # Define objective function for Optuna\n# def objective(trial):\n#     # Define hyperparameters to search\n#     params = {\n#         'booster': 'gbtree',\n#         'objective': 'binary:logistic',\n#         'eval_metric': 'auc',\n#         'max_depth': trial.suggest_int('max_depth', 3, 20),\n#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n#         'min_child_weight': trial.suggest_float('min_child_weight', 1, 15),\n#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n#         'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 10.0),\n#         'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 10.0),\n#         'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n#         'n_estimators': trial.suggest_int('n_estimators', 100, 12000),\n#         'device': 'cuda',\n#         'random_state': 0\n#     }\n\n#     # Split the training data into training and validation sets\n#     X_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n\n#     # Train XGBoost model with current hyperparameters\n#     clf = XGBClassifier(**params)\n#     clf.fit(X_train_split, y_train_split)\n\n#     # Predict probabilities on validation set\n#     y_pred_proba = clf.predict_proba(X_valid_split)[:, 1]\n\n#     # Calculate ROC AUC on validation set\n#     roc_auc = roc_auc_score(y_valid_split, y_pred_proba)\n#     return roc_auc\n\n# # Optimize hyperparameters using Optuna\n# study = optuna.create_study(direction='maximize')\n# study.optimize(objective, n_trials=50)\n\n# # Get best hyperparameters\n# xgb_best_params = study.best_params\n# print(\"Best Hyperparameters:\", xgb_best_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:00:31.991720Z","iopub.execute_input":"2024-11-27T15:00:31.992128Z","iopub.status.idle":"2024-11-27T15:00:32.001523Z","shell.execute_reply.started":"2024-11-27T15:00:31.992089Z","shell.execute_reply":"2024-11-27T15:00:31.997696Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Best Hyperparameters: {'max_depth': 15, 'learning_rate': 0.01801657172689155, 'min_child_weight': 4.8772240757900045, 'colsample_bytree': 0.6938100830879348, 'reg_alpha': 8.974794625892391, 'reg_lambda': 9.794363082142656, 'subsample': 0.628026726594587, 'n_estimators': 703}","metadata":{}},{"cell_type":"markdown","source":"Best Hyperparameters: {'max_depth': 3, 'learning_rate': 0.011670653230923514, 'min_child_weight': 14.127992761618438, 'colsample_bytree': 0.5038048654086844, 'reg_alpha': 5.760848133682294, 'reg_lambda': 2.6948173441150227, 'subsample': 0.5852808297867893, 'n_estimators': 3489}","metadata":{}},{"cell_type":"markdown","source":"Best Hyperparameters: {'max_depth': 4, 'learning_rate': 0.028949993238818562, 'min_child_weight': 7.472178342152908, 'colsample_bytree': 0.5048225534122298, 'reg_alpha': 8.993064644792046, 'reg_lambda': 3.4598638747943316, 'subsample': 0.5687531348526244, 'n_estimators': 750}","metadata":{}},{"cell_type":"markdown","source":"Best Hyperparameters: {'max_depth': 3, 'learning_rate': 0.05783817198027412, 'min_child_weight': 10.124475828112256, 'colsample_bytree': 0.6192098284876566, 'reg_alpha': 9.615639451753312, 'reg_lambda': 3.5778496101852357, 'subsample': 0.9446520676127865, 'n_estimators': 484}","metadata":{}},{"cell_type":"code","source":"# Split the training data to include a validation set for early stopping\nX_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\n# Create the XGBoost model using Optuna model\nxgb_best_params_1 = {'max_depth': 4, \n                    'learning_rate': 0.028949993238818562, \n                    'min_child_weight': 7.472178342152908, \n                    'colsample_bytree': 0.5048225534122298, \n                    'reg_alpha': 8.993064644792046, \n                    'reg_lambda': 3.4598638747943316, \n                    'subsample': 0.5687531348526244, \n                    'n_estimators': 750,\n                    'booster': 'gbtree',\n                    'objective': 'binary:logistic',\n                    'eval_metric': 'auc',\n                    'device': 'cuda',\n                    'random_state': 0}\nxgb_1 = XGBClassifier(**xgb_best_params_1)\n\n# Fit the model with early stopping\nxgb_1.fit(X_train_split, y_train_split,\n          eval_set=[(X_valid_split, y_valid_split)],\n          early_stopping_rounds=50,\n          verbose=500)\n\n# Predict probabilities on validation data\ny_pred_proba_xgb_1 = xgb_1.predict_proba(X_valid)[:, 1]\ny_pred_xgb_1 = np.round(y_pred_proba_xgb_1).astype(int)\n\n# Calculate Accuracy Score on validation data\nroc_auc = roc_auc_score(y_valid, y_pred_proba_xgb_1)\naccuracy = accuracy_score(y_valid, y_pred_xgb_1)\nprint(\"Accuracy Score on Validation Data:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:00:32.002861Z","iopub.execute_input":"2024-11-27T15:00:32.003307Z","iopub.status.idle":"2024-11-27T15:00:44.492516Z","shell.execute_reply.started":"2024-11-27T15:00:32.003267Z","shell.execute_reply":"2024-11-27T15:00:44.489269Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split the training data to include a validation set for early stopping\nX_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\n# Create the XGBoost model using Optuna model\nxgb_best_params_2 = {'max_depth': 3, \n                     'learning_rate': 0.05783817198027412, \n                     'min_child_weight': 10.124475828112256, \n                     'colsample_bytree': 0.6192098284876566, \n                     'reg_alpha': 9.615639451753312, \n                     'reg_lambda': 3.5778496101852357, \n                     'subsample': 0.9446520676127865, \n                     'n_estimators': 484}\nxgb_2 = XGBClassifier(**xgb_best_params_2)\n\n# Fit the model with early stopping\nxgb_2.fit(X_train_split, y_train_split,\n          eval_set=[(X_valid_split, y_valid_split)],\n          early_stopping_rounds=50,\n          verbose=500)\n\n# Predict probabilities on validation data\ny_pred_proba_xgb_2 = xgb_2.predict_proba(X_valid)[:, 1]\ny_pred_xgb_2 = np.round(y_pred_proba_xgb_2).astype(int)\n\n# Calculate Accuracy Score on validation data\nroc_auc = roc_auc_score(y_valid, y_pred_proba_xgb_2)\naccuracy = accuracy_score(y_valid, y_pred_xgb_2)\nprint(\"Accuracy Score on Validation Data:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:00:44.494634Z","iopub.execute_input":"2024-11-27T15:00:44.495131Z","iopub.status.idle":"2024-11-27T15:00:51.904565Z","shell.execute_reply.started":"2024-11-27T15:00:44.495088Z","shell.execute_reply":"2024-11-27T15:00:51.903300Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## CatBoost","metadata":{}},{"cell_type":"code","source":"# # Define objective function for Optuna\n# def objective(trial):\n#     # Define hyperparameters to search\n#     params = {\n#         'iterations': trial.suggest_int('iterations', 100, 1000),\n#         'depth': trial.suggest_int('depth', 4, 10),\n#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n#         'random_strength': trial.suggest_float('random_strength', 0.1, 10.0),\n#         'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n#         'border_count': trial.suggest_int('border_count', 1, 255),\n#         'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-5, 100),\n#         'scale_pos_weight': trial.suggest_float('scale_pos_weight', 0.01, 1.0),\n#         'eval_metric': 'AUC',\n#         'random_state': 0\n#     }\n\n#     # Split the training data into training and validation sets\n#     X_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n\n#     # Train CatBoost model with current hyperparameters\n#     clf = CatBoostClassifier(**params)\n#     clf.fit(X_train_split, y_train_split, eval_set=(X_valid_split, y_valid_split), verbose=0, early_stopping_rounds=50)\n\n#     # Predict probabilities on validation set\n#     y_pred_proba = clf.predict_proba(X_valid_split)[:, 1]\n\n#     # Calculate ROC AUC on validation set\n#     roc_auc = roc_auc_score(y_valid_split, y_pred_proba)\n#     return roc_auc\n\n# # Optimize hyperparameters using Optuna\n# study = optuna.create_study(direction='maximize')\n# study.optimize(objective, n_trials=50)\n\n# # Get best hyperparameters\n# cat_best_params = study.best_params\n# print(\"Best Hyperparameters:\", cat_best_params)","metadata":{"trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-11-27T15:00:51.906332Z","iopub.execute_input":"2024-11-27T15:00:51.906861Z","iopub.status.idle":"2024-11-27T15:00:51.913542Z","shell.execute_reply.started":"2024-11-27T15:00:51.906819Z","shell.execute_reply":"2024-11-27T15:00:51.912173Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Best Hyperparameters: {'iterations': 809, 'depth': 8, 'learning_rate': 0.16835084169271636, 'random_strength': 3.2449625766961097, 'bagging_temperature': 0.30055204865985985, 'border_count': 72, 'l2_leaf_reg': 34.289254984798575, 'scale_pos_weight': 0.841012500039096}","metadata":{}},{"cell_type":"markdown","source":"Best Hyperparameters: {'iterations': 707, 'depth': 6, 'learning_rate': 0.12929345186104244, 'random_strength': 3.5255746549441564, 'bagging_temperature': 0.39315065600806615, 'border_count': 231, 'l2_leaf_reg': 7.450462475101695, 'scale_pos_weight': 0.9507699352909662}","metadata":{}},{"cell_type":"markdown","source":"Best Hyperparameters: {'iterations': 750, 'depth': 5, 'learning_rate': 0.1498452500271287, 'random_strength': 2.3916541237913607, 'bagging_temperature': 0.7940046664760633, 'border_count': 255, 'l2_leaf_reg': 16.84665620855418, 'scale_pos_weight': 0.8657868473704984}","metadata":{}},{"cell_type":"code","source":"# Split the training data to include a validation set for early stopping\nX_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n\n# Create the CatBoost model using Optuna model\ncat_best_params_1 = {'iterations': 750, \n                   'depth': 5, \n                   'learning_rate': 0.1498452500271287, \n                   'random_strength': 2.3916541237913607, \n                   'bagging_temperature': 0.7940046664760633, \n                   'border_count': 255, \n                   'l2_leaf_reg': 16.84665620855418, \n                   'scale_pos_weight': 0.8657868473704984}\ncat_1 = CatBoostClassifier(**cat_best_params_1)\n\n# Fit the model with early stopping\ncat_1.fit(X_train_split, y_train_split,\n          eval_set=[(X_valid_split, y_valid_split)],\n          early_stopping_rounds=100,\n          verbose=500)\n\n# Predict probabilities on validation data\ny_pred_proba_cat_1 = cat_1.predict_proba(X_valid)[:, 1]\ny_pred_cat_1 = np.round(y_pred_proba_cat_1).astype(int)\n\n# Calculate Accuracy Score on validation data\nroc_auc = roc_auc_score(y_valid, y_pred_proba_cat_1)\naccuracy = accuracy_score(y_valid, y_pred_cat_1)\nprint(\"Accuracy Score on Validation Data:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:00:51.915409Z","iopub.execute_input":"2024-11-27T15:00:51.915958Z","iopub.status.idle":"2024-11-27T15:01:00.538261Z","shell.execute_reply.started":"2024-11-27T15:00:51.915913Z","shell.execute_reply":"2024-11-27T15:01:00.536635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split the training data to include a validation set for early stopping\nX_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n\n# Create the CatBoost model using Optuna model\ncat_best_params_2 = {'iterations': 179, \n                     'depth': 7, \n                     'learning_rate': 0.15525529979928837, \n                     'random_strength': 8.251760779808803, \n                     'bagging_temperature': 0.5813066735174205, \n                     'border_count': 222, \n                     'l2_leaf_reg': 14.7531039514028, \n                     'scale_pos_weight': 0.9981351356564279}\ncat_2 = CatBoostClassifier(**cat_best_params_2)\n\n# Fit the model with early stopping\ncat_2.fit(X_train_split, y_train_split,\n          eval_set=[(X_valid_split, y_valid_split)],\n          early_stopping_rounds=100,\n          verbose=500)\n\n# Predict probabilities on validation data\ny_pred_proba_cat_2 = cat_2.predict_proba(X_valid)[:, 1]\ny_pred_cat_2 = np.round(y_pred_proba_cat_2).astype(int)\n\n# Calculate Accuracy Score on validation data\nroc_auc = roc_auc_score(y_valid, y_pred_proba_cat_2)\naccuracy = accuracy_score(y_valid, y_pred_cat_2)\nprint(\"Accuracy Score on Validation Data:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:01:00.540366Z","iopub.execute_input":"2024-11-27T15:01:00.541359Z","iopub.status.idle":"2024-11-27T15:01:05.003209Z","shell.execute_reply.started":"2024-11-27T15:01:00.541310Z","shell.execute_reply":"2024-11-27T15:01:05.001924Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## LightGBM","metadata":{}},{"cell_type":"code","source":"# # Define objective function for Optuna\n# def objective(trial):\n#     # Define hyperparameters to search\n#     params = {\n#         'boosting_type': 'gbdt',\n#         'objective': 'binary',\n#         'metric': 'auc',\n#         'max_depth': trial.suggest_int('max_depth', 3, 10),\n#         'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n#         'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n#         'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n#         'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n#         'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n#         'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),\n#         'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n#         'random_state': 0,\n#         'verbose': -1\n#     }\n\n#     # Split the training data into training and validation sets\n#     X_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n\n#     # Train LightGBM model with current hyperparameters\n#     clf = LGBMClassifier(**params)\n#     clf.fit(X_train_split, y_train_split)\n\n#     # Predict probabilities on validation set\n#     y_pred_proba = clf.predict_proba(X_valid_split)[:, 1]\n\n#     # Calculate ROC AUC on validation set\n#     roc_auc = roc_auc_score(y_valid_split, y_pred_proba)\n#     return roc_auc\n\n# # Optimize hyperparameters using Optuna\n# study = optuna.create_study(direction='maximize')\n# study.optimize(objective, n_trials=50)\n\n# # Get best hyperparameters\n# lgb_best_params = study.best_params\n# print(\"Best Hyperparameters:\", lgb_best_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:01:05.004811Z","iopub.execute_input":"2024-11-27T15:01:05.005211Z","iopub.status.idle":"2024-11-27T15:01:05.011721Z","shell.execute_reply.started":"2024-11-27T15:01:05.005176Z","shell.execute_reply":"2024-11-27T15:01:05.010148Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Best Hyperparameters: {'max_depth': 3, 'num_leaves': 118, 'learning_rate': 0.10351217553076539, 'feature_fraction': 0.74365495415815, 'bagging_fraction': 0.6603938917764212, 'bagging_freq': 4, 'reg_alpha': 4.748837605697682, 'reg_lambda': 4.769270760614292, 'n_estimators': 199}","metadata":{}},{"cell_type":"markdown","source":"Best Hyperparameters: {'max_depth': 6, 'num_leaves': 99, 'learning_rate': 0.013072254029319857, 'feature_fraction': 0.6395233614280195, 'bagging_fraction': 0.796714605811389, 'bagging_freq': 3, 'reg_alpha': 5.261195256088222, 'reg_lambda': 2.9272237697785592, 'n_estimators': 886}","metadata":{}},{"cell_type":"markdown","source":"Best Hyperparameters: {'max_depth': 6, 'num_leaves': 20, 'learning_rate': 0.09192866255765324, 'feature_fraction': 0.5094500857265226, 'bagging_fraction': 0.6634973533057996, 'bagging_freq': 4, 'reg_alpha': 7.196198571360236, 'reg_lambda': 1.9539428468670361, 'n_estimators': 268}","metadata":{}},{"cell_type":"code","source":"# Split the training data to include a validation set for early stopping\nX_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n\n# Create the XGBoost model using Optuna model\nlgb_best_params_1 = {'max_depth': 6, \n                    'num_leaves': 99, \n                    'learning_rate': 0.013072254029319857, \n                    'feature_fraction': 0.6395233614280195, \n                    'bagging_fraction': 0.796714605811389, \n                    'bagging_freq': 3, \n                    'reg_alpha': 5.261195256088222, \n                    'reg_lambda': 2.9272237697785592, \n                    'n_estimators': 886,\n                    'boosting_type': 'gbdt',\n                    'objective': 'binary',\n                    'metric': 'auc',        \n                    'random_state': 0,\n                    'verbose': -1}\n\nlgb_1 = LGBMClassifier(**lgb_best_params_1)\n\n# Fit the model with early stopping\nlgb_1.fit(\n    X_train_split, y_train_split,\n    eval_set=[(X_valid_split, y_valid_split)],\n    callbacks=[early_stopping(100)]\n)\n\n# Predict probabilities on validation data\ny_pred_proba_lgb_1 = lgb_1.predict_proba(X_valid)[:, 1]\ny_pred_lgb_1 = np.round(y_pred_proba_lgb_1).astype(int)\n\n# Calculate Accuracy Score on validation data\naccuracy = accuracy_score(y_valid, y_pred_lgb_1)\nprint(\"Accuracy Score on Validation Data:\", accuracy)","metadata":{"trusted":true,"scrolled":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-11-27T15:01:05.013664Z","iopub.execute_input":"2024-11-27T15:01:05.014163Z","iopub.status.idle":"2024-11-27T15:01:19.331936Z","shell.execute_reply.started":"2024-11-27T15:01:05.014111Z","shell.execute_reply":"2024-11-27T15:01:19.330126Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split the training data to include a validation set for early stopping\nX_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n\n# Create the XGBoost model using Optuna model\nlgb_best_params_2 = {'max_depth': 6,\n                     'num_leaves': 20, \n                     'learning_rate': 0.09192866255765324, \n                     'feature_fraction': 0.5094500857265226, \n                     'bagging_fraction': 0.6634973533057996, \n                     'bagging_freq': 4, \n                     'reg_alpha': 7.196198571360236, \n                     'reg_lambda': 1.9539428468670361, \n                     'n_estimators': 268,\n                     'boosting_type': 'gbdt',\n                     'objective': 'binary',\n                     'metric': 'auc',        \n                     'random_state': 0,\n                     'verbose': -1}\n\nlgb_2 = LGBMClassifier(**lgb_best_params_2)\n\n# Fit the model with early stopping\nlgb_2.fit(\n    X_train_split, y_train_split,\n    eval_set=[(X_valid_split, y_valid_split)],\n    callbacks=[early_stopping(100)]\n)\n\n# Predict probabilities on validation data\ny_pred_proba_lgb_2 = lgb_2.predict_proba(X_valid)[:, 1]\ny_pred_lgb_2 = np.round(y_pred_proba_lgb_2).astype(int)\n\n# Calculate Accuracy Score on validation data\naccuracy = accuracy_score(y_valid, y_pred_lgb_2)\nprint(\"Accuracy Score on Validation Data:\", accuracy)","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2024-11-27T15:01:19.334272Z","iopub.execute_input":"2024-11-27T15:01:19.334826Z","iopub.status.idle":"2024-11-27T15:01:22.288987Z","shell.execute_reply.started":"2024-11-27T15:01:19.334776Z","shell.execute_reply":"2024-11-27T15:01:22.288114Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ensemble","metadata":{}},{"cell_type":"markdown","source":"## Voting Classifier","metadata":{}},{"cell_type":"code","source":"final_models = {\n    \"XGBClassifier_1\" : xgb_1,\n    \"XGBClassifier_2\" : xgb_2,\n    \"LGBMClassifier_1\": lgb_1,\n    \"LGBMClassifier_2\": lgb_2,\n    \"CatBoostClassifier_1\": cat_1,\n    \"CatBoostClassifier_2\": cat_2\n}\n\nfrom sklearn.ensemble import VotingClassifier\nmodel_voting =  VotingClassifier(estimators=[\n    ('XGBClassifier_1', final_models['XGBClassifier_1']),\n    ('XGBClassifier_2', final_models['XGBClassifier_2']),\n    ('LGBMClassifier_1', final_models['LGBMClassifier_1']),\n    ('LGBMClassifier_2', final_models['LGBMClassifier_2']),\n    ('CatBoostClassifier_1', final_models['CatBoostClassifier_1']),\n    ('CatBoostClassifier_2', final_models['CatBoostClassifier_2'])\n], voting=\"soft\")\n\nmodel_voting.fit(X_train, y_train)\n\n# Predict probabilities on validation data\ny_pred_proba_voting = model_voting.predict_proba(X_valid)[:, 1]\ny_pred_voting = np.round(y_pred_proba_voting).astype(int)","metadata":{"trusted":true,"scrolled":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-11-27T15:01:22.300210Z","iopub.execute_input":"2024-11-27T15:01:22.300656Z","iopub.status.idle":"2024-11-27T15:02:04.791725Z","shell.execute_reply.started":"2024-11-27T15:01:22.300604Z","shell.execute_reply":"2024-11-27T15:02:04.790526Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate Accuracy Score on validation data\naccuracy = accuracy_score(y_valid, y_pred_voting)\nprint(\"Accuracy Score on Validation Data:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:02:04.793306Z","iopub.execute_input":"2024-11-27T15:02:04.793843Z","iopub.status.idle":"2024-11-27T15:02:04.808074Z","shell.execute_reply.started":"2024-11-27T15:02:04.793796Z","shell.execute_reply":"2024-11-27T15:02:04.806610Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Optuna Voting","metadata":{}},{"cell_type":"code","source":"# Define the objective function\ndef objective(trial):\n    # Trial suggests weights for each model\n    w1 = trial.suggest_float(\"xgb_weight_1\", 0.0, 1.0)\n    w2 = trial.suggest_float(\"xgb_weight_2\", 0.0, 1.0)\n    w3 = trial.suggest_float(\"lgb_weight_1\", 0.0, 1.0)\n    w4 = trial.suggest_float(\"lgb_weight_2\", 0.0, 1.0)\n    w5 = trial.suggest_float(\"cat_weight_1\", 0.0, 1.0)\n    w6 = trial.suggest_float(\"cat_weight_2\", 0.0, 1.0)\n    \n    # Normalize weights to sum to 1\n    total_weight = w1 + w2 + w3 + w4 + w5 + w6\n    w1, w2, w3, w4, w5, w6 = w1 / total_weight, w2 / total_weight, w3 / total_weight, w4 / total_weight, w5 / total_weight, w6 / total_weight\n\n    # Compute weighted ensemble predictions\n    ensemble_pred_proba = (\n        w1 * y_pred_proba_xgb_1 +\n        w2 * y_pred_proba_xgb_2 +\n        w3 * y_pred_proba_lgb_1 +\n        w4 * y_pred_proba_lgb_2 +\n        w5 * y_pred_proba_cat_1 +\n        w6 * y_pred_proba_cat_2 \n    )\n\n    # Calculate accuracy (or other metric) and return as objective value\n    return roc_auc_score(y_valid, ensemble_pred_proba)\n\n# Run Optuna optimization\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=100)\n\n# Best weights and score\nprint(\"Best weights:\", study.best_params)\nprint(\"Best auc:\", study.best_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:02:04.809973Z","iopub.execute_input":"2024-11-27T15:02:04.810764Z","iopub.status.idle":"2024-11-27T15:02:09.575970Z","shell.execute_reply.started":"2024-11-27T15:02:04.810718Z","shell.execute_reply":"2024-11-27T15:02:09.574789Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_weights = study.best_params\nw1, w2, w3, w4, w5, w6 = best_weights[\"xgb_weight_1\"], best_weights[\"xgb_weight_2\"], best_weights[\"lgb_weight_1\"], best_weights[\"lgb_weight_2\"], best_weights[\"cat_weight_1\"], best_weights[\"cat_weight_2\"]\n# Normalize the weights\ntotal_weight = w1 + w2 + w3 + w4 + w5 + w6 \nw1, w2, w3, w4, w5, w6 = w1 / total_weight, w2 / total_weight, w3 / total_weight, w4 / total_weight, w5 / total_weight, w6 / total_weight\n\n# Compute weighted ensemble predictions\nensemble_pred_proba = (\n    w1 * y_pred_proba_xgb_1 +\n    w2 * y_pred_proba_xgb_2 +\n    w3 * y_pred_proba_lgb_1 +\n    w4 * y_pred_proba_lgb_2 +\n    w5 * y_pred_proba_cat_1 +\n    w6 * y_pred_proba_cat_2 \n)\n\nensemble_pred = (ensemble_pred_proba > 0.5).astype(int)\n\n# Calculate Accuracy Score on validation data\naccuracy = accuracy_score(y_valid, ensemble_pred)\nprint(\"Accuracy Score on Validation Data:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:02:09.577920Z","iopub.execute_input":"2024-11-27T15:02:09.578331Z","iopub.status.idle":"2024-11-27T15:02:09.595017Z","shell.execute_reply.started":"2024-11-27T15:02:09.578293Z","shell.execute_reply":"2024-11-27T15:02:09.593696Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Stacking Classifier","metadata":{}},{"cell_type":"code","source":"# final_models = {\n#     \"XGBClassifier\" : xgb_1,\n#     \"LGBMClassifier\": lgb_1,\n#     \"CatBoostClassifier\": cat_1\n# }\n\n# from sklearn.ensemble import StackingClassifier\n# model_stacking =  StackingClassifier(estimators=[\n#     ('XGBClassifier', final_models['XGBClassifier']),\n#     ('LGBMClassifier', final_models['LGBMClassifier']),\n#     ('CatBoostClassifier', final_models['CatBoostClassifier'])],\n#                            final_estimator=xgb_1)\n\n# model_stacking.fit(X_train, y_train)\n\n# # Predict probabilities on validation data\n# y_pred_proba_stacking = model_stacking.predict_proba(X_valid)[:, 1]\n# y_pred_stacking = np.round(y_pred_proba_stacking).astype(int)","metadata":{"trusted":true,"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2024-11-27T15:02:09.596374Z","iopub.execute_input":"2024-11-27T15:02:09.596883Z","iopub.status.idle":"2024-11-27T15:02:09.609567Z","shell.execute_reply.started":"2024-11-27T15:02:09.596847Z","shell.execute_reply":"2024-11-27T15:02:09.608148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Combine predictions using weighted average\ny_pred_proba_weighted = (0.1 * y_pred_proba_xgb_1 + 0.9 * y_pred_proba_xgb_2 \n                         + 0.1 * y_pred_proba_lgb_1 + 0.9 * y_pred_proba_lgb_2 \n                         + 0.8 * y_pred_proba_cat_1 +  0.2 * y_pred_proba_cat_2)/3\n\n# Perform weighted average\ny_pred_weighted = np.round(y_pred_proba_weighted).astype(int)\n\n# Calculate ROC AUC on validation data\nroc_auc_weighted = roc_auc_score(y_valid, y_pred_proba_weighted)\nprint(\"ROC AUC on Validation Data:\", roc_auc_weighted)\n\n# Calculate Accuracy Score on validation data\naccuracy = accuracy_score(y_valid, y_pred_weighted)\nprint(\"Accuracy Score on Validation Data:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:23:42.444281Z","iopub.execute_input":"2024-11-27T15:23:42.444735Z","iopub.status.idle":"2024-11-27T15:23:42.477487Z","shell.execute_reply.started":"2024-11-27T15:23:42.444693Z","shell.execute_reply":"2024-11-27T15:23:42.476312Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ensemble with AutoML","metadata":{}},{"cell_type":"markdown","source":"## Weighted Average and Optuna Weights","metadata":{}},{"cell_type":"code","source":"# Combine predictions using weighted average\ny_pred_proba_weighted = 0.01 * (\n                    0.1 * y_pred_proba_xgb_1 +\n                    0.9 * y_pred_proba_xgb_2 +\n                    0.1 * y_pred_proba_lgb_1 +\n                    0.9 * y_pred_proba_lgb_2 +\n                    0.8 * y_pred_proba_cat_1 +\n                    0.2 * y_pred_proba_cat_2) + 0.99 * y_pred_proba_automl_1\n\n# Perform weighted average\ny_pred_weighted = np.round(y_pred_proba_weighted).astype(int)\n\n# Calculate ROC AUC on validation data\nroc_auc_weighted = roc_auc_score(y_valid, y_pred_proba_weighted)\nprint(\"ROC AUC on Validation Data:\", roc_auc_weighted)\n\n# Calculate Accuracy Score on validation data\naccuracy = accuracy_score(y_valid, y_pred_weighted)\nprint(\"Accuracy Score on Validation Data:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:24:06.055765Z","iopub.execute_input":"2024-11-27T15:24:06.056196Z","iopub.status.idle":"2024-11-27T15:24:06.094997Z","shell.execute_reply.started":"2024-11-27T15:24:06.056159Z","shell.execute_reply":"2024-11-27T15:24:06.093552Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Weighted Average and Voting Classifier","metadata":{}},{"cell_type":"code","source":"# # Combine predictions using soft voting\n# y_pred_proba_voting_weighted = (0.05 * y_pred_proba_voting + \n#                                 0.95 * y_pred_proba_automl_1)\n\n# # Perform soft voting\n# y_pred_voting_weighted = np.round(y_pred_proba_voting_weighted).astype(int)\n\n# # Calculate ROC AUC on validation data\n# roc_auc_voting_weighted = roc_auc_score(y_valid, y_pred_proba_voting_weighted)\n# print(\"ROC AUC on Validation Data:\", roc_auc_voting_weighted)\n\n# # Calculate Accuracy Score on validation data\n# accuracy = accuracy_score(y_valid, y_pred_voting_weighted)\n# print(\"Accuracy Score on Validation Data:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:02:09.665390Z","iopub.execute_input":"2024-11-27T15:02:09.665728Z","iopub.status.idle":"2024-11-27T15:02:09.671068Z","shell.execute_reply.started":"2024-11-27T15:02:09.665696Z","shell.execute_reply":"2024-11-27T15:02:09.669827Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Weighted Average and Stacking Classifier","metadata":{}},{"cell_type":"code","source":"# # Combine predictions using soft voting\n# y_pred_proba_stacking_weighted = (0.05 * y_pred_proba_stacking + \n#                                   0.95 * y_pred_proba_automl_1)\n\n# # Perform soft voting\n# y_pred_stacking_weighted = np.round(y_pred_proba_stacking_weighted).astype(int)\n\n# # Calculate ROC AUC on validation data\n# roc_auc_stacking_weighted = roc_auc_score(y_valid, y_pred_proba_stacking_weighted)\n# print(\"ROC AUC on Validation Data:\", roc_auc_stacking_weighted)\n\n# # Calculate Accuracy Score on validation data\n# accuracy = accuracy_score(y_valid, y_pred_stacking_weighted)\n# print(\"Accuracy Score on Validation Data:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:02:09.672928Z","iopub.execute_input":"2024-11-27T15:02:09.673797Z","iopub.status.idle":"2024-11-27T15:02:09.686349Z","shell.execute_reply.started":"2024-11-27T15:02:09.673740Z","shell.execute_reply":"2024-11-27T15:02:09.685148Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Final Prediction","metadata":{}},{"cell_type":"code","source":"# y_pred_proba_test_xgb_1 = xgb_1.predict_proba(df_test_processed)[:, 1]\n# y_pred_proba_test_cat_1 = cat_1.predict_proba(df_test_processed)[:, 1]\n# y_pred_proba_test_lgb_1 = lgb_1.predict_proba(df_test_processed)[:, 1]\n\n# # Voting Ensemble\n# y_pred_proba_test_voting_1 = model_voting.predict_proba(df_test_processed)[:, 1]\n# y_pred_proba_test_automl_1 = automl.predict(df_test_processed).data[:, 0]\n\n# y_pred_proba_test_ensemble = (0.05 * y_pred_proba_test_voting_1 +\n#                               0.95 * y_pred_proba_test_automl_1)\n\n# y_pred_proba_test_ensemble = np.round(y_pred_proba_test_ensemble).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:02:09.687970Z","iopub.execute_input":"2024-11-27T15:02:09.688598Z","iopub.status.idle":"2024-11-27T15:02:09.703025Z","shell.execute_reply.started":"2024-11-27T15:02:09.688528Z","shell.execute_reply":"2024-11-27T15:02:09.701893Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred_proba_test_xgb_1 = xgb_1.predict_proba(df_test_processed)[:, 1]\ny_pred_proba_test_xgb_2 = xgb_2.predict_proba(df_test_processed)[:, 1]\ny_pred_proba_test_cat_1 = cat_1.predict_proba(df_test_processed)[:, 1]\ny_pred_proba_test_cat_2 = cat_2.predict_proba(df_test_processed)[:, 1]\ny_pred_proba_test_lgb_1 = lgb_1.predict_proba(df_test_processed)[:, 1]\ny_pred_proba_test_lgb_2 = lgb_2.predict_proba(df_test_processed)[:, 1]\n\ny_pred_proba_test_automl_1 = automl.predict(df_test_processed).data[:, 0]\n\ny_pred_proba_test_ensemble = 0.01 * (\n               0.1 * y_pred_proba_test_xgb_1 +\n               0.9 * y_pred_proba_test_xgb_2 +\n               0.1 * y_pred_proba_test_lgb_1 +\n               0.9 * y_pred_proba_test_lgb_2 +\n               0.8 * y_pred_proba_test_cat_1 +\n               0.2 * y_pred_proba_test_cat_2) + 0.99 * y_pred_proba_test_automl_1\ny_pred_test_ensemble = np.round(y_pred_proba_test_ensemble).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:16:20.631648Z","iopub.execute_input":"2024-11-27T15:16:20.632129Z","iopub.status.idle":"2024-11-27T15:16:56.295140Z","shell.execute_reply.started":"2024-11-27T15:16:20.632091Z","shell.execute_reply":"2024-11-27T15:16:56.294212Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/playground-series-s4e11/sample_submission.csv')\n\nsubmission['Depression'] = y_pred_test_ensemble.astype(int)\n#submission['Depression'] = predictions_df['predict']\nsubmission.to_csv('submission_ensemble.csv', index=False)\nsubmission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:02:46.016655Z","iopub.execute_input":"2024-11-27T15:02:46.017942Z","iopub.status.idle":"2024-11-27T15:02:46.149602Z","shell.execute_reply.started":"2024-11-27T15:02:46.017886Z","shell.execute_reply":"2024-11-27T15:02:46.148195Z"}},"outputs":[],"execution_count":null}]}